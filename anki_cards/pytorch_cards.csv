"Front","Back"
"什么是PyTorch？","PyTorch是一个由Facebook AI Research团队开发的开源深度学习框架。它以其灵活性、易用性和强大的GPU加速能力而闻名，是学术界和工业界最流行的深度学习框架之一。"
"PyTorch的核心数据结构是什么？它与NumPy数组有何不同？","PyTorch的核心数据结构是张量（Tensor）。它类似于NumPy的nd-array，但有两个关键区别：1. 张量可以在GPU上进行计算以实现大规模加速。 2. 张量可以自动跟踪其计算历史，用于自动求导（Autograd）。"
"什么是PyTorch的“动态计算图 (Dynamic Computation Graph)”？它有什么优势？","PyTorch在运行时构建计算图。这意味着图的结构可以在每次迭代中改变。这种“即时定义”（Define-by-Run）的方式提供了极大的灵活性，使得处理动态输入（如变长序列）和进行复杂的模型设计变得非常直观和容易，同时也便于使用标准的Python调试工具。"
"PyTorch中的`autograd`引擎是做什么用的？","`autograd`是PyTorch的自动微分引擎。当你对张量执行操作时，它会自动记录这些操作，构建一个计算图。当你对最终结果调用`.backward()`时，`autograd`会沿着这个图反向传播，自动计算出所有参与计算的张量（特别是模型参数）相对于最终结果的梯度。这是神经网络训练的核心。"
"在PyTorch中，`nn.Module`的作用是什么？","`nn.Module`是所有神经网络模块的基类。构建自定义网络时，通常需要继承`nn.Module`。它提供了一些核心功能，如自动跟踪模型的所有参数（`model.parameters()`），以及方便地在训练模式和评估模式之间切换（`model.train()` / `model.eval()`）。"
"PyTorch中的优化器 (Optimizer) 是如何工作的？","优化器（如`torch.optim.Adam`或`torch.optim.SGD`）负责根据计算出的梯度来更新模型的参数。在训练循环中，典型的步骤是：1. `optimizer.zero_grad()` 清除旧的梯度。 2. `loss.backward()` 计算新的梯度。 3. `optimizer.step()` 根据新计算的梯度更新模型参数。"
"PyTorch中的`DataLoader`有什么作用？","`DataLoader`是一个实用工具，它将数据集（Dataset）包装成一个迭代器。它可以自动处理数据批处理（batching）、数据打乱（shuffling）和使用多进程并行加载数据，从而极大地简化和加速了数据加载过程。"
"PyTorch和TensorFlow的主要区别是什么？","**计算图**：PyTorch以动态图著称，灵活易用；TensorFlow 1.x是静态图，部署高效，但TF 2.x也默认采用动态图。**API设计**：PyTorch的API被认为更“Pythonic”，更直观；TensorFlow的API更全面，生态更成熟。**社区**：PyTorch在学术研究领域更受欢迎；TensorFlow在工业生产部署方面有更长的历史和更完整的工具链。"
"什么是TorchScript？它为什么对生产部署很重要？","TorchScript是一种将PyTorch模型从纯Python代码转换为可以在高性能环境中（如C++）独立运行的表示形式的方法。它通过即时（JIT）编译器将模型序列化，使其脱离Python环境的依赖，并进行优化，这对于将模型部署到生产服务器或移动设备上至关重要。"
"PyTorch 2.0引入的`torch.compile`有什么主要好处？","`torch.compile`是PyTorch 2.0的核心功能，它通过使用新的编译器技术，在不改变用户代码的情况下，显著提升模型的训练和推理速度（官方称通常有30%-200%的加速）。"
