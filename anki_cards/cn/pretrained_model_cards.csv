"Front","Back","TAGS"
"什么是预训练模型 (Pre-trained Model)？","预训练模型是在大规模数据集（如维基百科、ImageNet）上经过长时间训练，已经学习到通用特征和知识的深度学习模型。它可以被用作新任务的起点，从而避免从零开始训练。","PretrainedModel"
"使用预训练模型的生动比喻是什么？","预训练模型就像一个已经完成了“通识教育”的大学毕业生。他具备了广泛的基础知识和学习能力（预训练），当他进入特定工作岗位时，只需要进行短暂的“专业培训”（微调），就能快速胜任新工作。","PretrainedModel"
"什么是迁移学习 (Transfer Learning)？","迁移学习是一种机器学习技术，指的是将一个在源任务上学到的知识和技能（由预训练模型承载）应用到一个不同但相关的目标任务上。其核心思想是利用已有的知识来加速新知识的学习。","PretrainedModel"
"使用预训练模型进行迁移学习时，主要有两种策略，它们是什么？","1. **特征提取 (Feature Extraction)**：冻结预训练模型的所有或大部分层，将其作为一个固定的特征提取器，只训练新添加的输出层。 2. **微调 (Fine-tuning)**：不仅训练新的输出层，还“解冻”预训练模型顶部的几层，用较低的学习率在目标任务数据上进行训练，以微调其参数。","PretrainedModel"
"什么时候应该选择“特征提取”策略？","当目标任务的数据集非常小，或者计算资源非常有限时，应优先选择特征提取。因为微调在小数据集上容易过拟合，而特征提取只训练输出层，参数少，不易过拟合且计算成本低。","PretrainedModel"
"什么时候应该选择“微调 (Fine-tuning)”策略？","当目标任务的数据集较大且与预训练模型的数据集相似时，微调通常能获得更好的性能。它允许模型更好地适应新数据的特定特征。","PretrainedModel"
"使用预训练模型有哪些主要优势？","1. **节省时间和计算成本**：无需从零开始训练，大大缩短开发周期。 2. **提高模型性能**：预训练模型已从大规模数据中学到丰富的特征，通常能达到更高的准确率。 3. **降低数据需求**：对于特定任务，只需要相对较少的标注数据就能达到很好的效果。","PretrainedModel"
"什么是领域适应 (Domain Adaptation)？","领域适应是迁移学习的一种特例，指的是将一个在源数据分布（源领域）上训练好的模型，应用到一个数据分布不同但任务相同的目标领域。例如，将一个在新闻文章上训练的情感分析模型，应用到电影评论上。","PretrainedModel"
"什么是零样本学习 (Zero-shot Learning) 和少样本学习 (Few-shot Learning)？","**零样本学习**指模型在没有见过任何特定任务的标注样本的情况下，直接执行该任务的能力。**少样本学习**指模型仅通过极少数（如1-5个）标注样本就能快速学会执行新任务。这两种能力都得益于预训练模型强大的泛化知识。","PretrainedModel"
"什么是参数高效微调 (Parameter-Efficient Fine-Tuning, PEFT)？","PEFT是一系列旨在只微调模型少量参数（而不是全部参数）的技术，例如LoRA、Adapter等。它能以接近全参数微调的性能，极大地降低大规模预训练模型的微调成本和存储需求。","PretrainedModel"