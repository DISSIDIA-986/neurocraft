"Front","Back","TAGS"
"What is the core intuition behind Diffusion Models?","It's a two-step process: 1. **Destroy:** Systematically and slowly add noise to an image until it becomes pure static. 2. **Create:** Train a neural network to learn how to reverse this process, step-by-step. By learning to 'denoise' the static, the model can create a brand new image from a random noise input.","Diffusion"
"Use an analogy to explain how a Diffusion Model generates an image.","Imagine a sculptor starting with a rough, shapeless block of marble (pure noise). The sculptor has a perfect memory of how a finished statue weathers away into a block of marble (the noising process). To create a new statue, they simply reverse this memory, carefully chipping away the 'weathering' (noise) bit by bit, until a beautiful, clear statue (image) emerges.","Diffusion"
"What is the main advantage of Diffusion Models over GANs?","**Training Stability and Sample Quality.** GANs involve a difficult 'cat-and-mouse' game between two networks that can often fail (mode collapse). Diffusion models have a more stable training process and have consistently produced higher-quality, more diverse, and more detailed images than top-tier GANs.","Diffusion"
"What is the main *disadvantage* of Diffusion Models?","**Slow Sampling Speed.** Because generation requires a slow, iterative denoising process (often hundreds or thousands of steps), creating an image is much slower than with a GAN, which typically requires only a single pass through a network.","Diffusion"
"How do models like DALL-E or Stable Diffusion use text to guide image generation?","This is called **conditional generation**. During the denoising (creation) process, the model isn't just given the noisy image; it's also given an embedding of the text prompt (e.g., 'an astronaut riding a horse'). This text acts as a guide, influencing the denoising at each step to ensure the final image matches the description.","Diffusion"
