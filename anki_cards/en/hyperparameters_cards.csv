"Front","Back","TAGS"
"What is the difference between a model parameter and a hyperparameter?","**Model parameters** are learned *by the model* from the data during training (e.g., the weights in a neural network). **Hyperparameters** are set *by the developer* before training begins, to configure the model or control the training process (e.g., the learning rate). Think of parameters as the knowledge in a student's brain, and hyperparameters as the study schedule you give them.","Hyperparameters"
"What is the 'learning rate' and why is it a critical hyperparameter?","The learning rate determines how big of a step the model takes when updating its parameters during training. A rate that is **too high** can cause the model to overshoot the optimal solution, while a rate that is **too low** will cause it to learn very slowly. Finding a good learning rate is crucial for efficient training.","Hyperparameters"
"What is Grid Search for hyperparameter tuning? What is its main drawback?","Grid Search is an exhaustive search method. You define a 'grid' of possible hyperparameter values, and it trains and evaluates a model for *every single combination*. Its main drawback is the **curse of dimensionality**: the number of combinations explodes as you add more hyperparameters, making it computationally very expensive and slow.","Hyperparameters"
"Why is Random Search often more effective than Grid Search?","Random Search simply tries a fixed number of random combinations from the hyperparameter space. It's often more effective because not all hyperparameters are equally important. Grid Search wastes a lot of time on unimportant parameters, while Random Search has a better chance of landing on a good value for the *few* parameters that truly matter.","Hyperparameters"
"What is Bayesian Optimization for hyperparameter tuning?","It's a 'smart' search method. It uses the results from previous trials to build a probabilistic model of the relationship between hyperparameters and performance. It then uses this model to intelligently choose the next set of hyperparameters to try, focusing on areas that are most likely to yield improvement. It's generally much more efficient than Grid Search or Random Search.","Hyperparameters"
"What is the role of a 'validation set' in hyperparameter tuning?","The validation set is a separate portion of your training data used to evaluate the model's performance for a given set of hyperparameters. You should **never** use your final test set for this, as it would 'leak' information from the test set into your model selection process, giving you an overly optimistic and invalid measure of your model's true performance on unseen data.","Hyperparameters"
