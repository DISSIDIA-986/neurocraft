"Front","Back","TAGS"
"What is a Large Language Model (LLM)?","An LLM is a massive neural network (usually a Transformer) trained on vast amounts of text data. Its fundamental goal is to understand and generate human language by learning to predict the next word in a sequence. This simple objective, when scaled up, leads to surprising 'emergent abilities.'","LLM"
"What are 'Emergent Abilities' in LLMs?","These are surprising skills that are not explicitly programmed but appear spontaneously when a model becomes very large. Examples include the ability to perform arithmetic, translate languages, write code, and use logic, which are not seen in smaller models.","LLM"
"What is the difference between Pre-training and Fine-tuning for an LLM?","**Pre-training** is the unsupervised, computationally massive first step where the model learns general language patterns from a huge corpus of text (like the entire internet). **Fine-tuning** is a much cheaper second step where the pre-trained model is further trained on a smaller, specific dataset to adapt it for a particular task (like being a helpful chatbot).","LLM"
"What is 'Prompt Engineering'?","Prompt engineering is the art and science of designing effective inputs (prompts) to guide an LLM to produce a desired output. It's like learning how to ask a very smart, literal-minded person exactly the right question to get the answer you want.","LLM"
"What is 'Chain-of-Thought' (CoT) Prompting?","CoT is an advanced prompting technique that improves an LLM's reasoning ability. Instead of just asking for the final answer, you instruct the model to 'think step-by-step' and lay out its reasoning process. This often leads to more accurate results for complex logic or math problems.","LLM"
"What does it mean for an LLM to 'hallucinate'?","Hallucination is when an LLM confidently generates text that is factually incorrect, nonsensical, or completely fabricated. It's a major challenge because the model doesn't 'know' it's making things up; it's simply generating plausible-sounding sequences of words.","LLM"
"What is 'Alignment' in the context of LLMs?","Alignment is the process of steering an LLM's behavior to be helpful, honest, and harmless, and to follow human values and intentions. This is typically achieved through techniques like Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF).","LLM"
"What are Scaling Laws for LLMs?","Scaling Laws are an observed phenomenon where the performance of an LLM predictably improves as you increase three key factors: the size of the model (number of parameters), the amount of training data, and the amount of computation used for training. This predictability has been a major driving force in the development of larger and larger models.","LLM"
